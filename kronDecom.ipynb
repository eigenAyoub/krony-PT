{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac980831-496d-42c0-b146-08bcff40d34c",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "1. Load the weights \n",
    "2. Kronecker Decomp.:\n",
    "   * $K$ into $K_1, K_2$\n",
    "   * $Q$ into $Q_1, Q_2$\n",
    "3. check the attention\n",
    "   * Project the matrix\n",
    "   * Optimize $K Q^T$ and check correctness of compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9314d95-069a-4e41-8a18-4e76d0f45b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 219 kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "\n",
    "def kronecker_decompose(A: Tensor, m: int, n: int, *, k: int = 1, niter: int = 10) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "\n",
    "      Frobenius-optimal decomposition of `A` into a sum of `k` Kronecker products.\n",
    "      Algorithm from Van Loan and Pitsianis (1993),\n",
    "      \"Approximation with Kronecker Products\"\n",
    "      <https://bit.ly/46hT5aY>.\n",
    "\n",
    "    Args:\n",
    "        A: Matrix or batch of matrices to decompose, of shape (..., m * m2, n * n2)\n",
    "        m: Desired number of rows in the left Kronecker factor(s)\n",
    "        n: Desired number of columns in the left Kronecker factor(s)\n",
    "        k: Number of Kronecker factors\n",
    "        niter: Number of iterations for the low rank SVD algorithm\n",
    "    Returns:\n",
    "        Tuple of Kronecker factors (`left`, `right`) of shape `(..., k, m, n)` and\n",
    "        `(..., k, A.shape[-2] // m, A.shape[-1] // n)` respectively.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the dimensions of `A` are not compatible with the desired\n",
    "            number of rows and columns in the left Kronecker factor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    m2, n2 = A.shape[-2] // m, A.shape[-1] // n\n",
    "    assert A.shape[-2:] == (m * m2, n * n2), \"Dimensions do not match\"\n",
    "\n",
    "    # Reshape and permute A, then perform SVD\n",
    "    A = rearrange(A, \"... (m m2) (n n2) -> ... (m n) (m2 n2)\", m=m, m2=m2, n=n, n2=n2)\n",
    "    u, s, v = torch.svd_lowrank(A, q=k, niter=niter)\n",
    "\n",
    "    # Unflatten the factors\n",
    "    u = rearrange(u, \"... (m n) k -> ... k m n\", m=m, n=n, k=k)\n",
    "    v = rearrange(v, \"... (m2 n2) k -> ... k m2 n2\", m2=m2, n2=n2, k=k)\n",
    "\n",
    "    scale = s[..., None, None].sqrt()\n",
    "    return u * scale, v * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load('out-shakespeare-char/ckpt.pt')\n",
    "checkpoint_model_args = checkpoint['model_args']\n",
    "\n",
    "#model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
    "#                  bias=bias, vocab_size=None, dropout=dropout) # start with model_args from command line\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size', 'dropout']),\n",
       " dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'config']))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_model_args.keys(), checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.ln_f.weight\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "\n",
    "for i, j in state_dict.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1152, 384]),\n",
       " torch.Size([384, 384]),\n",
       " torch.Size([384, 384]),\n",
       " torch.Size([384, 384]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_q_v = state_dict[\"transformer.h.0.attn.c_attn.weight\"]\n",
    "\n",
    "kk,q,v = k_q_v.split(384, dim=0)\n",
    "\n",
    "k_q_v.shape, kk.shape, q.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([384, 192]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1, k2  = kronecker_decompose(kk, 384, 192 ,k=2)\n",
    "q1, q2  = kronecker_decompose(q, 384, 192, k=2)\n",
    "v1, v2  = kronecker_decompose(v, 384, 192, k=2)\n",
    "\n",
    "k1[0].shape, k2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0309,  0.0374,  0.0180,  ...,  0.0112,  0.0632, -0.0764],\n",
       "        [-0.0830,  0.1004, -0.0485,  ...,  0.0371,  0.0017, -0.0020],\n",
       "        [-0.0405,  0.0490,  0.0092,  ...,  0.0081, -0.0278,  0.0336],\n",
       "        ...,\n",
       "        [ 0.0804, -0.0972,  0.0399,  ..., -0.0204, -0.0327,  0.0396],\n",
       "        [-0.0142,  0.0172, -0.0006,  ..., -0.0371, -0.0044,  0.0054],\n",
       "        [-0.0096,  0.0116, -0.0151,  ...,  0.0752, -0.0128,  0.0154]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.zeros(384, 384)\n",
    "\n",
    "s = s.to(device)\n",
    "\n",
    "for i in range(1):\n",
    "    s += torch.kron(q1[i], q2[i])\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([384, 384]), torch.Size([384, 384]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.kron(k1[1], k2[1])\n",
    "Q = torch.kron(q1[1], q2[1])\n",
    "\n",
    "K.shape, Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_dir': 'out-shakespeare-char',\n",
       " 'eval_interval': 250,\n",
       " 'log_interval': 10,\n",
       " 'eval_iters': 200,\n",
       " 'eval_only': False,\n",
       " 'always_save_checkpoint': False,\n",
       " 'init_from': 'scratch',\n",
       " 'wandb_log': False,\n",
       " 'wandb_project': 'shakespeare-char',\n",
       " 'wandb_run_name': 'mini-gpt',\n",
       " 'dataset': 'shakespeare_char',\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'batch_size': 64,\n",
       " 'block_size': 256,\n",
       " 'n_layer': 6,\n",
       " 'n_head': 6,\n",
       " 'n_embd': 384,\n",
       " 'dropout': 0.2,\n",
       " 'bias': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'max_iters': 5000,\n",
       " 'weight_decay': 0.1,\n",
       " 'beta1': 0.9,\n",
       " 'beta2': 0.99,\n",
       " 'grad_clip': 1.0,\n",
       " 'decay_lr': True,\n",
       " 'warmup_iters': 100,\n",
       " 'lr_decay_iters': 5000,\n",
       " 'min_lr': 0.0001,\n",
       " 'backend': 'nccl',\n",
       " 'device': 'cuda',\n",
       " 'dtype': 'bfloat16',\n",
       " 'compile': True}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seqlen, n_embd = 64, 256, 384\n",
    "\n",
    "x = torch.randn(batch_size, seqlen, n_embd, device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 256, 384]), torch.Size([64, 256, 384]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk = x@K\n",
    "xq = x@Q.transpose()\n",
    "\n",
    "xk.shape, xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "384 / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1452955411.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[130], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    Add this to your pytorch series    XW   always batch sizes first\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "m = nn.Linear(20, 30)\n",
    "ii = torch.randn(128, 20)\n",
    "output = m.forward(ii)\n",
    "output.shape\n",
    "\n",
    "\n",
    "Add this to your pytorch series    XW   always batch sizes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
